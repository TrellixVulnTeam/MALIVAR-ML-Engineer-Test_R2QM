# MALIVAR-ML-Engineer-Test
Тестовое задание посвященное генерации лица с выбранными параметрами с возможностью дальнейшего редактирования.

# Задача
Задача состоит из двух частей:

1. Генерация несуществующего человека с возможностью редактирования лица.
Скрипт с множеством гиперпараметров или окно с элементами управления.
2. Скрипт, который генерирует изображения ранее сгенерированного человека (головы) с комбинацией различных вращений и выражений лица.

# Write-up "Как я это сделал"
__TL;DR__  
DiscoFaceGan не подошел, ConfigNet идеальный вариант для второго задания, transparent latent-space GAN - для первого задания. Изменен TLGan так, чтобы можно было сохранить изображение. Написан скрипт для генерации датасета на основе ConfigNet. S-R - опционален из за долгой работы, вместо него можно применить билинейную интерполяцию.

Поначалу задача казалась невыполнимой, потому что опыта с GAN совершенно не было, а были только поверхностные знания. Однако, можно использовать open-source проекты и первый же запрос в гугл _"GAN Face Generation"_ выдал мне статью о __DiscoFaceGan__ от Microsoft. Сперва она казалась идеальным вариантом, однако проблема данной GAN состояла в следующем: все лица генерировались по входному вектору, который задавался случайным образом по стандартному нормальному распределению. Так как по заданию нужно было генерировать лицо с параметрами (пол, возраст, цвет кожи и т.д.), то данная модель не подходила. Поэтому было решено отказаться от данной модели.   
Далее по поиску в ODS по запросу _"DiscoFaceGAN"_ случайно наткнулся на статью о __ConfigNet__. После изучения материала, оказалась, что данная GAN позволяла загрузить в нее собственную картинку и отредактировать ее (повернуть, добавить эмоции, изменить волосы, повернуть глаза и т.д.). Следовательно, вторая часть задания найдена.  
_"Image Editing by Manipulating Latent Space, Facial Attributes Editing"_ по данным тэгам была найдена и __transparent latent-space GAN__. Данная модель позволяла генерировать лицо с выбранными параметрами. В ходе работы был немного расширен функционал, который позволял бы сохранять сгенерированное изображение для использования во втором задании.  
Для генерации датасета был написан скрипт, базирующийся на работе ConfigNet.  
Также, была небольшая проблема в ConfigNet: разрешение выходных изображений было 512х512 или 256х256. Поэтому далее было два пути: с помощью open-cv увеличить разрешение или же найти модели Super-Resolution. В вышеописанном скрипте был добавлен параметр, который применял бы S-R или билинейную интерполяцию для генерации изображений 1024х1024.  
В качестве модели S-R была найдена __Single Image Super-Resolution with EDSR, WDSR and SRGAN__ на _Papers with code_. И выбрана реализация на tensorflow для того, чтобы соединить с уже написанным кодом. Однако, применение Super-Resolution к каждому изображению занимает длительное время из-за вычислений на CPU, поэтому и было решено сделать применение данной функции опциональным.  
### В данной работе использовались
* Nvidea GeForce 960 4Gb VRAM
* Python 3.6
* CUDA 10.1
* cuDNN v7.6.5
# 1 часть задания
Для выполнения первой части задания был найден и изучен open-source проект __TL-GAN: transparent latent-space GAN__ (https://github.com/SummitKwan/transparent_latent_gan).

## Установка и запуск
### Создание виртуального окружения для данной части задания  
```
    > python -m venv venvtlgan

    > venvtlgan\Scripts\activate
```
### Установка зависимостей и запуск  
1. ```cd``` (в корневую директорию проекта).  

```
    > cd transparent_latent_gan  

    > pip install -r requirements.txt
```
2. Вручную загрузите предварительно обученную модель pg-GAN из [dropbox](https://www.dropbox.com/sh/y1ryg8iq1erfcsr/AAB--PO5qAapwp8ILcgxE2I6a?dl=0).
3. Распакуйте загруженные файлы и поместите их в каталог проекта в следующем формате:
```
root
    asset_model
        karras2018iclr-celebahq-1024x1024.pkl
        cnn_face_attr_celeba
            model_20180927_032934.h5
    asset_results
        pg_gan_celeba_feature_direction_40
            feature_direction_20181002_044444.pkl
    src
        ...
    static
        ...
    ...
```
4. Запустите jupyter ноутбук (потребуется загрузить соответствующую библиотеку) из ```./src/notebooks/tl_gan_ipywidgets_gui.ipynb``` 
5. В GUI можно настроить лицо несуществующего человека с выбранными параметрами  для использования изображения во второй части задания и сохранить в ```<корневой каталог репозитория>\img\test.png```, которая находится в корневой папке репозитория.

### Пример работы  
      
![Alt text](./gifs/online_demo_run_fast_01.gif?raw=true "Title")  

Данный проект был расширен только путем добавления кнопки _Save image_. В данном окне с элементами управления можно изменить: 
* пол;
* возраст;
* цвет кожи;
* челку, линию роста волос, лысину;
* размер, заостренность носа;
* макияж;
* улыбку, открытый рот;
* волнистые, белые, черные, серые волосы;
* бороду, эспаньолку, бакенбарды;
* очки, серьги, галстук.  

Также есть возможность изменения остальных параметров при фиксации определенного параметра.

# 2 часть задания
Во второй части задания использовался open-source проект __CONFIG: Controllable Neural Face Image Generation__ (https://arxiv.org/pdf/2005.02671.pdf) (https://github.com/microsoft/ConfigNet).

## Установка
### Создание виртуального окружения для 2-ой части задания  
Перед данным действием требуется покинуть виртуальное окружение 1-ого задания.
```
    > python -m venv venvconfignet

    > venvconfignet\Scripts\activate
```
### Установка зависимостей и вспомогательных компонентов
1. ```cd``` (в корневую директорию проекта).  
```
    > pip install -r setup/requirements.txt
```
2. Если вы используете Windows, загрузите и настройте OpenFace автоматически, запустив 
```
    > python setup/download_deps.py
```
3. Если вы используете другие ОС, вам нужно будет установить OpenFace в соответствии с [инструкциями](https://github.com/TadasBaltrusaitis/OpenFace/wiki/Unix-Installation), вам также нужно будет указать путь к OpenFace в ```confignet/face_image_normalizer.py```
4. Загрузите файл [model.zip](https://github.com/microsoft/ConfigNet/releases/download/v1.0.0/models.zip), содержащий предварительно обученные модели, и извлеките его в корневой каталог репозитория.
5. Также потребуется загрузить модель повышения разрешения __Single Image Super-Resolution with EDSR, WDSR and SRGAN__ (https://github.com/krasserm/super-resolution). Для этого следует загрузить [предварительно обученные веса](https://martin-krasser.de/sisr/weights-srgan.tar.gz) и распаковать в папку ```evaluation\```
## Запуск
```
    > python evaluation/generate_dataset_my.py --image_path <путь к изображению> --max_angle <угол отклонения лица> --enable_sr <применить/отключить S-R>
```
1. <путь к изображению> - путь к сгенерированному изображению в предыдущем задании. Должен оканчиваться на ```...<корневой каталог репозитория>\img\test.png```
2. <угол отклонения лица> - под углом подразумевается число, которое задает диапазон поворота головы. Например ```--max_angle 60 ``` позволит сгенерировать датасет, в котором рысканье и тангаж будут изменяться от -60 до 60 градусов с шагом 5.
3. <применить/отключить S-R> - позволяет включить/отключить применение Super-Resolution к выходным изображениям. 1 - включить, 0 - отключить. В случае отключенного режима, выходное изображение также будет с разрешением 1024х1024, однако вместо S-R будет применен метод билинейной интерполяции для увеличения расширения картинки (ConfigNet на выходе выдает разрешение 512х512 или 256х256). Также S-R выполняется полностью на CPU, что замедлит генерацию датасета.  

Данная команда сгенерирует в папке ```<корневой каталог репозитория>/dataset/``` изображения сгенерированного лица в 1-ом задании с поворотами от -60 до 60 градусов, затем со случайными поворотами лица, глаз и различными эмоциями (100 изображений) с применением S-R.
```
    > python evaluation/generate_dataset_my.py --image_path <путь к изображению>
```

## Пример работы
Из данной картинки после отработки скрипта был получен датасет с различными поворотами и выражениями лица в разрешении 1024х1024.
![image info](./gifs/test.png)
Собственно датасет
![image info](./gifs/dataset.png)